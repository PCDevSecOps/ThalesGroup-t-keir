# -*- coding: utf-8 -*-
"""Convert source document to tkeir indexer document
Author: Eric Blaudez (Eric Blaudez)

Copyright (c) 2020 by THALES
"""

from thot.core.ThotLogger import ThotLogger, LogUserContext
from thot.tasks.ner.NERTaggerConfiguration import NERTaggerConfiguration
from thot.tasks.ner.NERTagger import NERTagger
import os
import unittest
import base64


class TestNERTagger(unittest.TestCase):

    def test_tagger(self):
        dir_path = os.path.dirname(os.path.realpath(__file__))
        res_path = os.path.abspath(os.path.join(dir_path, "../../../app/projects/default/resources/modeling/tokenizer/en"))
        TestNERTagger.tagger_config["named-entities"]["label"][0]["resources-base-path"] = res_path
        config = NERTaggerConfiguration()
        config.loads(TestNERTagger.tagger_config)
        ThotLogger.loads(config.logger_config.configuration)
        cid = "autogenerated-" + str("xxx")
        log_context = LogUserContext(cid)
        ThotLogger.loads(config.logger_config.configuration)

        text = [
            "He lives at Paris , and works at Valero Energy. His email is jd@paris.fr. He works on the document published by john et al."
        ]
        tkeir_doc = {
            "data_source": "tokenizer-service",
            "source_doc_id": "file://test.txt",
            "title": "Access to UBSWenergy Production Environment",
            "content": text,
            "title_tokens": [
                {"token": "Access", "start_sentence": True},
                {"token": "to", "start_sentence": False},
                {"token": "UBSWenergy", "start_sentence": False},
                {"token": "Production", "start_sentence": False},
                {"token": "Environment", "start_sentence": False},
                {"token": "by", "start_sentence": False},
                {"token": "John", "start_sentence": False},
                {"token": "Doe", "start_sentence": False},
            ],
            "content_tokens": [
                {"token": "He", "start_sentence": True},
                {"token": "lives", "start_sentence": False},
                {"token": "at", "start_sentence": False},
                {"token": "Paris", "start_sentence": False},
                {"token": ",", "start_sentence": False},
                {"token": "and", "start_sentence": False},
                {"token": "works", "start_sentence": False},
                {"token": "at", "start_sentence": False},
                {"token": "Valero Energy", "start_sentence": False},
                {"token": ".", "start_sentence": False},
                {"token": "His", "start_sentence": False},
                {"token": "email", "start_sentence": False},
                {"token": "is", "start_sentence": False},
                {"token": "jd@paris.fr", "start_sentence": False},
                {"token": ".", "start_sentence": False},
                {"token": "He", "start_sentence": True},
                {"token": "works", "start_sentence": False},
                {"token": "on", "start_sentence": False},
                {"token": "the", "start_sentence": False},
                {"token": "document", "start_sentence": False},
                {"token": "published", "start_sentence": False},
                {"token": "by", "start_sentence": False},
                {"token": "john", "start_sentence": False},
                {"token": "et", "start_sentence": False},
                {"token": "al", "start_sentence": False},
                {"token": ".", "start_sentence": False},
            ],
            "title_morphosyntax": [
                {"pos": "NOUN", "lemma": "access", "text": "Access"},
                {"pos": "ADP", "lemma": "to", "text": "to"},
                {"pos": "PROPN", "lemma": "UBSWenergy", "text": "UBSWenergy"},
                {"pos": "PROPN", "lemma": "Production", "text": "Production"},
                {"pos": "PROPN", "lemma": "Environment", "text": "Environment"},
                {"pos": "ADP", "lemma": "by", "text": "by"},
                {"pos": "PROPN", "lemma": "John", "text": "John"},
                {"pos": "PROPN", "lemma": "Doe", "text": "Doe"},
            ],
            "content_morphosyntax": [
                {"pos": "PRON", "lemma": "he", "text": "He"},
                {"pos": "VERB", "lemma": "live", "text": "lives"},
                {"pos": "ADP", "lemma": "at", "text": "at"},
                {"pos": "PROPN", "lemma": "Paris", "text": "Paris"},
                {"pos": "PUNCT", "lemma": ",", "text": ","},
                {"pos": "CCONJ", "lemma": "and", "text": "and"},
                {"pos": "VERB", "lemma": "work", "text": "works"},
                {"pos": "ADP", "lemma": "at", "text": "at"},
                {"pos": "PROPN", "lemma": "Valero Energy", "text": "Valero Energy"},
                {"pos": "PUNCT", "lemma": ".", "text": "."},
                {"pos": "PRON", "lemma": "his", "text": "His"},
                {"pos": "NOUN", "lemma": "email", "text": "email"},
                {"pos": "VERB", "lemma": "be", "text": "is"},
                {"pos": "ADJ", "lemma": "jd@paris.fr", "text": "jd@paris.fr"},
                {"pos": "PUNCT", "lemma": ".", "text": "."},
                {"pos": "PRON", "lemma": "he", "text": "He"},
                {"pos": "VERB", "lemma": "work", "text": "works"},
                {"pos": "ADP", "lemma": "on", "text": "on"},
                {"pos": "DET", "lemma": "the", "text": "the"},
                {"pos": "NOUN", "lemma": "document", "text": "document"},
                {"pos": "VERB", "lemma": "publish", "text": "published"},
                {"pos": "ADP", "lemma": "by", "text": "by"},
                {"pos": "PROPN", "lemma": "john", "text": "john"},
                {"pos": "NOUN", "lemma": "et", "text": "et"},
                {"pos": "PROPN", "lemma": "al", "text": "al"},
                {"pos": "PUNCT", "lemma": ".", "text": "."},
            ],
        }
        tagger = NERTagger(config=config, call_context=log_context)
        tkeir_doc = tagger.tag(tkeir_doc)
        title_ner = [{"start": 6, "end": 8, "label": "person", "text": "John Doe"}]
        content_ner = [
            {"start": 3, "end": 4, "label": "location", "text": "Paris"},
            {"start": 8, "end": 9, "label": "organization", "text": "Valero Energy"},
            {"start": 13, "end": 14, "label": "email", "text": "jd@paris.fr"},
            {"start": 22, "end": 25, "label": "cite_person", "text": "john et al"},
        ]
        self.assertEqual(tkeir_doc["content_ner"], content_ner)
        self.assertEqual(tkeir_doc["title_ner"], title_ner)

    def test_ner_mwe(self):
        config = NERTaggerConfiguration()
        config.loads(TestNERTagger.tagger_config)
        ThotLogger.loads(config.logger_config.configuration)
        cid = "autogenerated-" + str("xxx")
        log_context = LogUserContext(cid)
        tkeir_doc = {
            "content": ["The delice is a town in city 5000.\n\n"],
            "content_morphosyntax": [
                {"lemma": "the", "pos": "DET", "text": "The"},
                {"lemma": "delice", "pos": "NOUN", "text": "delice"},
                {"lemma": "be", "pos": "VERB", "text": "is"},
                {"lemma": "a", "pos": "DET", "text": "a"},
                {"lemma": "town", "pos": "NOUN", "text": "town"},
                {"lemma": "in", "pos": "ADP", "text": "in"},
                {"lemma": "city", "pos": "NOUN", "text": "city"},
                {"lemma": "5000", "pos": "NUM", "text": "5000"},
                {"lemma": ".", "pos": "PUNCT", "text": "."},
            ],
            "content_tokens": [
                [
                    [
                        {"start_sentence": True, "token": "The"},
                        {"start_sentence": False, "token": "delice"},
                        {"start_sentence": False, "token": "is"},
                        {"start_sentence": False, "token": "a"},
                        {"start_sentence": False, "token": "town"},
                        {"start_sentence": False, "token": "in"},
                        {"start_sentence": False, "token": "city"},
                        {"start_sentence": False, "token": "5000"},
                        {"start_sentence": False, "token": "."},
                    ]
                ]
            ],
            "data_source": "converter-service",
            "error": False,
            "kg": [],
            "source_doc_id": "file:///home/tkeir_svc/tkeir/thot/tests/data/test-raw/raw-target/ner.txt",
            "tasks-info": [],
            "title": "",
            "title_morphosyntax": [],
        }
        tagger = NERTagger(config=config, call_context=log_context)
        tkeir_doc = tagger.tag(tkeir_doc)
        self.assertEqual(tkeir_doc["title_ner"], [])
        self.assertEqual(tkeir_doc["content_ner"], [])
