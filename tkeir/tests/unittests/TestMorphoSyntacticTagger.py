# -*- coding: utf-8 -*-
"""Convert source document to tkeir indexer document
Author: Eric Blaudez (Eric Blaudez)

Copyright (c) 2020 by THALES
"""

from thot.core.ThotLogger import ThotLogger, LogUserContext
from thot.tasks.morphosyntax.MorphoSyntacticTaggerConfiguration import MorphoSyntacticTaggerConfiguration
from thot.tasks.morphosyntax.MorphoSyntacticTagger import MorphoSyntacticTagger
import json
import unittest
import base64


class TestMorphoSyntacticTagger(unittest.TestCase):

    tagger_config = {
        "logger": {"logging-level": "debug"},
        "morphosyntax": {
            "taggers": [
                {
                    "language": "en",
                    "resources-base-path": "/home/tkeir_svc/tkeir/thot/tests/data",
                    "mwe": "tkeir_mwe.pkl",
                    "pre-sentencizer": True,
                    "pre-tagging-with-concept": True,
                    "add-concept-in-knowledge-graph": True,
                }
            ],
            "network": {
                "host": "0.0.0.0",
                "port": 8080,
                "associate-environment": {"host": "HOST_ENVNAME", "port": "PORT_ENVNAME"},
            },
            "runtime": {
                "request-max-size": 100000000,
                "request-buffer-queue-size": 100,
                "keep-alive": True,
                "keep-alive-timeout": 5,
                "graceful-shutown-timeout": 15.0,
                "request-timeout": 60,
                "response-timeout": 60,
                "workers": 1,
            },
            "serialize": {
                "input": {"path": "/tmp", "keep-service-info": True},
                "output": {"path": "/tmp", "keep-service-info": True},
            },
        },
    }

    def test_tagger_star(self):
        config = MorphoSyntacticTaggerConfiguration()
        config.loads(TestMorphoSyntacticTagger.tagger_config)
        ThotLogger.loads(config.logger_config.configuration)
        cid = "autogenerated-" + str("xxx")
        log_context = LogUserContext(cid)
        text = [
            [" this is a __underscored text__ with _ and __ to use a sp_lit. stars for news * research and development * list."]
        ]
        tkeir_doc = {
            "data_source": "tokenizer-service",
            "source_doc_id": "file://test.txt",
            "title": "none",
            "content": text,
            "content_tokens": [
                [
                    [
                        [
                            {"token": "this", "start_sentence": True, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "is", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "a", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "_", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "_", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "underscored", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "text", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "_", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "_", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "with", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "_", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "and", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "_", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "_", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "to", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "use", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "a", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "sp_lit", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": ".", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                        ],
                        [
                            {"token": "stars", "start_sentence": True, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "for", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "News", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "*", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "Research", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "and", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "Development", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "*", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": "List", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                            {"token": ".", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                        ],
                    ]
                ]
            ],
            "content_title": "",
        }
        tagger = MorphoSyntacticTagger(config=config, call_context=log_context)
        tkeir_doc = tagger.tag(tkeir_doc)

    def test_tagger(self):
        config = MorphoSyntacticTaggerConfiguration()
        config.loads(TestMorphoSyntacticTagger.tagger_config)
        ThotLogger.loads(config.logger_config.configuration)
        cid = "autogenerated-" + str("xxx")
        log_context = LogUserContext(cid)
        text = ["He lives at paris, and works at Valero Energy."]
        tkeir_doc = {
            "data_source": "tokenizer-service",
            "source_doc_id": "file://test.txt",
            "title": "Access to UBSWenergy Production Environment",
            "content": text,
            "title_tokens": [
                {"token": "Access", "start_sentence": True},
                {"token": "to", "start_sentence": False},
                {"token": "UBSWenergy", "start_sentence": False},
                {"token": "Production", "start_sentence": False},
                {"token": "Environment", "start_sentence": False},
            ],
            "content_tokens": [
                {"token": "He", "start_sentence": True},
                {"token": "lives", "start_sentence": False},
                {"token": "at", "start_sentence": False},
                {"token": "paris", "start_sentence": False},
                {"token": ",", "start_sentence": False},
                {"token": "and", "start_sentence": False},
                {"token": "works", "start_sentence": False},
                {"token": "at", "start_sentence": False},
                {"token": "Valero Energy", "start_sentence": False},
                {"token": ".", "start_sentence": False},
            ],
        }
        tagger = MorphoSyntacticTagger(config=config, call_context=log_context)
        tkeir_doc = tagger.tag(tkeir_doc)

        self.assertEqual(
            tkeir_doc["title_morphosyntax"],
            [
                {"pos": "NOUN", "lemma": "access", "text": "Access", "is_oov": False, "is_sent_start": True},
                {"pos": "ADP", "lemma": "to", "text": "to", "is_oov": False, "is_sent_start": False},
                {"pos": "PROPN", "lemma": "UBSWenergy", "text": "UBSWenergy", "is_oov": True, "is_sent_start": False},
                {"pos": "PROPN", "lemma": "Production", "text": "Production", "is_oov": False, "is_sent_start": False},
                {"pos": "PROPN", "lemma": "Environment", "text": "Environment", "is_oov": False, "is_sent_start": False},
            ],
        )

        self.assertEqual(
            tkeir_doc["content_morphosyntax"],
            [
                {"pos": "PRON", "lemma": "he", "text": "He", "is_oov": False, "is_sent_start": True},
                {"pos": "VERB", "lemma": "live", "text": "lives", "is_oov": False, "is_sent_start": False},
                {"pos": "ADP", "lemma": "at", "text": "at", "is_oov": False, "is_sent_start": False},
                {"pos": "PROPN", "lemma": "paris", "text": "paris", "is_oov": False, "is_sent_start": False},
                {"pos": "PUNCT", "lemma": ",", "text": ",", "is_oov": False, "is_sent_start": False},
                {"pos": "CCONJ", "lemma": "and", "text": "and", "is_oov": False, "is_sent_start": False},
                {"pos": "VERB", "lemma": "work", "text": "works", "is_oov": False, "is_sent_start": False},
                {"pos": "ADP", "lemma": "at", "text": "at", "is_oov": False, "is_sent_start": False},
                {"pos": "PROPN", "lemma": "Valero Energy", "text": "Valero Energy", "is_oov": True, "is_sent_start": False},
                {"pos": "PUNCT", "lemma": ".", "text": ".", "is_oov": False, "is_sent_start": False},
            ],
        )

    def test_pos_assignation(self):
        config = MorphoSyntacticTaggerConfiguration()
        config.loads(TestMorphoSyntacticTagger.tagger_config)
        ThotLogger.loads(config.logger_config.configuration)
        cid = "autogenerated-" + str("xxx")
        log_context = LogUserContext(cid)
        tkeir_doc = {
            "data_source": "tokenizer-service",
            "source_doc_id": "file://test.txt",
            "title": "",
            "content": "the poly[2,4-(pipérazin-1,4-yl)-6-(morpholin-4-yl)-1,3,5-triazine] is a basic polymer with nothing in common with Tow Truck Operator, it was developed at Aix La Chapelle",
            "title_tokens": [],
            "content_tokens": [
                [
                    {"token": "the", "start_sentence": True, "mwe": {"is-compound": False, "data": {}}},
                    {
                        "token": "poly[2,4-(pipérazin-1,4-yl)-6-(morpholin-4-yl)-1,3,5-triazine]",
                        "start_sentence": False,
                        "mwe": {
                            "data": {
                                "chemistry-terminology": {
                                    "pos": "NOUN",
                                    "data": [{"type": "concept", "concept": "piperazine"}],
                                    "weight": 10,
                                }
                            },
                            "is-compound": False,
                        },
                    },
                    {"token": "is", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                    {"token": "a", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                    {"token": "basic", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                    {"token": "polymer", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                    {"token": "with", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                    {"token": "nothing", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                    {"token": "in", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                    {"token": "common", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                    {"token": "with", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                    {
                        "token": "Tow Truck Operator",
                        "start_sentence": False,
                        "mwe": {
                            "is-compound": True,
                            "data": {
                                "jobtitle": {"pos": "NOUN", "data": [{"type": "concept", "concept": "operator"}], "weight": 10}
                            },
                        },
                    },
                    {"token": ",", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                    {"token": "it", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                    {"token": "was", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                    {"token": "developed", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                    {"token": "at", "start_sentence": False, "mwe": {"is-compound": False, "data": {}}},
                    {
                        "token": "Aix La Chapelle",
                        "start_sentence": False,
                        "mwe": {
                            "is-compound": True,
                            "data": {"location.city": {"pos": "PROPN", "data": [{"type": "named-entity"}], "weight": 10}},
                        },
                    },
                ]
            ],
        }
        tagger = MorphoSyntacticTagger(config=config, call_context=log_context)
        tkeir_doc = tagger.tag(tkeir_doc)
