# -*- coding: utf-8 -*-
"""Convert source document to tkeir indexer document
Author : Eric Blaudez (Eric Blaudez)

Copyright (c) 2022 THALES 
All Rights Reserved.
"""
from sanic import Sanic
from sanic.exceptions import ServerError
import sanic.response
from sanic.exceptions import NotFound

import os
import sys
import json
import argparse
import traceback
import gc
from uuid import uuid4


dir_path = os.path.dirname(os.path.realpath(__file__))
sys.path.insert(0, os.path.abspath(os.path.join(dir_path, "../../")))
sys.path.insert(0, os.path.abspath(os.path.join(dir_path, "../")))
sys.path.insert(0, os.path.abspath(os.path.join(dir_path, "./")))

from thot import __author__, __copyright__, __credits__, __maintainer__, __email__, __status__
import thot.core.Constants as Constants
from thot.core.ThotLogger import ThotLogger, LogUserContext
from thot.core.ThotMetrics import ThotMetrics
from thot.core.Constants import exception_error_and_trace
from thot.core.Utils import generate_id, type_to_bool
from thot.tasks.tokenizer import __version_tokenizer__, __date_tokenizer__
from thot.tasks.tokenizer.TokenizerConfiguration import TokenizerConfiguration
from thot.tasks.tokenizer.Tokenizer import Tokenizer
from thot.tasks.tokenizer.AnnotationConfiguration import AnnotationConfiguration
from thot.tasks.tokenizer.AnnotationResources import AnnotationResources


# Global variables
app = Sanic("tokenizer-service")
app.config["API_VERSION"] = __version_tokenizer__
app.config["API_TITLE"] = "Tokenizer Service"
app.config["API_DESCRIPTION"] = "Tokenize document in tkeir format (generally coming from converter service)"
app.config["API_CONTACT_EMAIL"] = __email__


class TokenizerEngine:
    """Store tokenizer as singleton
    Warning args should be set before calls
    """

    tokenizer = None
    tokenizerConfiguration = None
    args = None
    count_run = 0

    @staticmethod
    def get_config():
        """create an return configuration as singleton

        Returns:
            TokenizerConfiguration: return the tokenizer configuration load through args
        """
        if not TokenizerEngine.tokenizerConfiguration:
            TokenizerEngine.tokenizerConfiguration = TokenizerConfiguration()
            with open(TokenizerEngine.args.config) as fh:
                TokenizerEngine.tokenizerConfiguration.load(fh)
                fh.close()
        return TokenizerEngine.tokenizerConfiguration

    @staticmethod
    def getTokenizer():
        """create and return tokenizer as singleton

        Returns:
            Tokenizer:  return the tokenizer
        """
        if not TokenizerEngine.tokenizer:
            TokenizerEngine.tokenizer = Tokenizer(config=TokenizerEngine.get_config())
        return TokenizerEngine.tokenizer

    @staticmethod
    def reloadAt(max_count):
        TokenizerEngine.count_run = TokenizerEngine.count_run + 1
        if TokenizerEngine.count_run > max_count:
            TokenizerEngine.count_run = 0
            del TokenizerEngine.tokenizer
            gc.collect()
            TokenizerEngine.tokenizer = Tokenizer(config=TokenizerEngine.get_config())
            ThotLogger.info("Free memory, prevent memory leak")


tokenizer_engine = None


def service_config():
    app.config.update(
        {
            "CONFIGURATION_FILE": TokenizerEngine.args.config,
        }
    )
    app.config["FALLBACK_ERROR_FORMAT"] = "json"


def service_not_loaded(call_context):
    call_context["status"] = 500
    ThotLogger.error("Service not loaded", context=call_context)
    return sanic.response.json(
        {"error": Constants.SERVICE_NOT_LOADED, "version": __version_tokenizer__, "date": __date_tokenizer__},
        headers={"X-Served-By": "tkeir/tokenizer"},
        status=500,
    )


@app.listener("before_server_start")
async def setup_config(app, loop):
    service_config()


@app.listener("after_server_start")
def init(sanic, loop):
    global tokenizer_engine
    cid = "autogenerated-" + str(uuid4())
    log_context = LogUserContext(cid)
    tokenizer_engine = {
        "id": generate_id(prefix="tokenizer"),
        "ppid": os.getppid(),
        "pid": os.getpid(),
        "run": TokenizerEngine.getTokenizer(),
    }
    ThotLogger.info(Constants.SERVICE_LOADED, context=log_context)


def sanic_bad_parameter_response(error_description, call_context=None):
    return sanic.response.json(
        {
            "error": error_description,
            "info": tokenizer_engine["id"],
            "config": app.config["CONFIGURATION_FILE"],
            "version": __version_tokenizer__,
            "date": __date_tokenizer__,
        },
        headers={"X-Served-By": "tkeir/tokenizer"},
        status=422,
    )


@app.route("/api/tokenizer/run", methods=["POST", "OPTIONS"])
async def run_service(request):
    no_x_correlation = "autogenerated-" + str(uuid4())
    cid = request.headers.get("x-Correlation-id") or no_x_correlation
    log_context = LogUserContext(cid)
    if not tokenizer_engine:
        ThotMetrics.increment_counter(short_name="tokenizer-run", path="/api/tokenizer/run", method="post", status=500)
        return service_not_loaded(log_context)
    try:

        tokenize_status = 200
        data = tokenizer_engine["run"].tokenize(request.json, call_context=log_context)
        if data["error"]:
            tokenize_status = 500
        ThotMetrics.increment_counter(
            short_name="tokenizer-run", path="/api/tokenizer/run", method="post", status=tokenize_status
        )
        return sanic.response.json(
            {
                "results": data,
                "info": tokenizer_engine["id"],
                "config": app.config["CONFIGURATION_FILE"],
                "version": __version_tokenizer__,
                "date": __date_tokenizer__,
            },
            headers={"X-Served-By": "tkeir/tokenizer"},
            status=tokenize_status,
        )
    except Exception as e:
        log_context["status"] = 500
        ThotLogger.error(
            "Exception occured", trace=exception_error_and_trace(str(e), str(traceback.format_exc())), context=log_context
        )
        return sanic.response.json(
            {
                "error": Constants.SERVICE_INTERNAL_ERROR,
                "exception": str(e),
                "trace": str(traceback.format_exc()),
                "info": tokenizer_engine["id"],
                "config": app.config["CONFIGURATION_FILE"],
                "version": __version_tokenizer__,
                "date": __date_tokenizer__,
            },
            headers={"X-Served-By": "tkeir/tokenizer"},
            status=500,
        )


@app.route("/api/tokenizer/health", methods=["GET", "POST", "OPTIONS"])
async def health(request):
    no_x_correlation = "autogenerated-" + str(uuid4())
    cid = request.headers.get("x-correlation-id") or no_x_correlation
    log_context = LogUserContext(cid)
    if not tokenizer_engine:
        ThotMetrics.increment_counter(short_name="tokenizer-health", path="/api/tokenizer/health", method="get", status=500)
        return service_not_loaded(log_context)
    ThotMetrics.increment_counter(short_name="tokenizer-health", path="/api/tokenizer/health", method="get", status=200)
    return sanic.response.json(
        {
            "health": Constants.SERVICE_HEALTH_OK,
            "info": tokenizer_engine["id"],
            "config": app.config["CONFIGURATION_FILE"],
            "version": __version_tokenizer__,
            "date": __date_tokenizer__,
        },
        headers={"X-Served-By": "tkeir/tokenizer"},
        status=200,
    )


@app.route("/metrics", methods=["GET", "POST", "OPTIONS"])
async def metrics(request):
    output = ThotMetrics.generateMetricsResponse().decode("utf-8")
    content_type = ThotMetrics.METRIC_MIME_TYPE
    return sanic.response.text(body=output, content_type=content_type)


@app.exception(NotFound)
async def function_not_found(request, exception):
    no_x_correlation = "autogenerated-" + str(uuid4())
    cid = request.headers.get("x-correlation-id") or no_x_correlation
    log_context = LogUserContext(cid)
    if not tokenizer_engine:
        return service_not_loaded(log_context)
    return sanic.response.json(
        {
            "error": Constants.SERVICE_PAGE_NOT_FOUND,
            "info": tokenizer_engine["id"],
            "config": app.config["CONFIGURATION_FILE"],
            "version": __version_tokenizer__,
            "date": __date_tokenizer__,
        },
        headers={"X-Served-By": "tkeir/tokenizer"},
        status=404,
    )


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("-c", "--config", default=None, type=str, help="configuration file")
    parser.add_argument("-i", "--init", default=False, action="store_true", help="Initializer resources")
    args = parser.parse_args()
    TokenizerEngine.args = args
    if not TokenizerEngine.args.config:
        ThotLogger.loads()
        ThotLogger.error("Configuration file is mandatory")
        sys.exit(-1)

    try:
        # initialize logger
        ThotLogger.loads(TokenizerEngine.get_config().logger_config.configuration, logger_name="Tokenizer")
        ThotMetrics.APP_NAME = "T-KEIR : tokenizer"
        ThotMetrics.create_counter(
            short_name="tokenizer-health", function_name="health", counter_description="Health function count"
        )
        ThotMetrics.create_counter(
            short_name="tokenizer-run", function_name="run", counter_description="run_service function count"
        )
        host = TokenizerEngine.get_config().net_config.configuration["network"]["host"]
        port = int(TokenizerEngine.get_config().net_config.configuration["network"]["port"])
        workers = TokenizerEngine.get_config().runtime_config.configuration["runtime"]["workers"]
        use_ssl = os.getenv("TKEIR_USE_SSL", "True")
        if args.init:
            tokenizer_config = TokenizerEngine.get_config().configuration
            mwefile = os.path.join(
                tokenizer_config["segmenters"][0]["resources-base-path"], tokenizer_config["segmenters"][0]["mwe"]
            )

            annotation_file = os.path.join(
                tokenizer_config["segmenters"][0]["resources-base-path"],
                tokenizer_config["segmenters"][0]["annotation-resources-reference"],
            )
            try:
                with open(annotation_file) as config_f:
                    a_config = json.load(config_f)
                    config_f.close()
                    annot_config = AnnotationConfiguration()
                    annot_modeling = AnnotationResources()
                    ThotLogger.loads(a_config, logger_name="annotation")
                    annot_config.loads(a_config)
                    annot_modeling.createModel(annot_config.configuration, mwefile)
            except Exception as e:
                print("An error occured. " + Constants.exception_error_and_trace(str(e), str(traceback.format_exc())))
                sys.exit(-1)
            sys.exit(0)
        if ("ssl" in TokenizerEngine.get_config().net_config.configuration["network"]) and type_to_bool(use_ssl):
            ThotLogger.info("Run service with SSL")
            app.run(
                host=host,
                port=port,
                workers=workers,
                ssl=TokenizerEngine.get_config().net_config.configuration["network"]["ssl"],
            )
        else:
            app.run(host=host, port=port, workers=workers)
    except Exception as e:
        ThotLogger.error("An error occured." + Constants.exception_error_and_trace(str(e), str(traceback.format_exc())))
        sys.exit(-1)


if __name__ == "__main__":
    main()
